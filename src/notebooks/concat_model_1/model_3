{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_2_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJn36JfoSlO6",
        "colab_type": "text"
      },
      "source": [
        "## SoCal Housing Price Prediction\n",
        "\n",
        "**Dataset: [https://www.kaggle.com/ted8080/house-prices-and-images-socal/data#](https://www.kaggle.com/ted8080/house-prices-and-images-socal/data#)**</br></br>\n",
        "Machine learning based model aimed at predicting housing prices of homes in the Southern California area using a combination of tabular home data (ie. rooms, square footage, city, etc.) and a photo of the home facade.\n",
        "\n",
        "**Group Members**</br>\n",
        "Matan Broner</br>\n",
        "Fernando Guerra</br>\n",
        "HaoYu Zhu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzFsUB4KD0zK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set verbose settings up here\n",
        "# Verbose = 0 => No output\n",
        "# Verbose = 1 => Only textual output will be printed\n",
        "# Verbose = 2 => Both textual and graphical output will be printed\n",
        "verbose = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz-UApkcH1S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Module used to display the loss functions in the training models\n",
        "!pip3 install livelossplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JT2RWkXybh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Block ensures that TensorFlow 2.0 is being used\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQwqd7LtwI6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base Imports\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import locale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u5W0G82qb4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive\n",
        "# To make this block work, ensure that you have the dataset linked below in your Google Drive at /Datasets/house-prices-and-images-socal.zip\n",
        "# Dataset: https://www.kaggle.com/ted8080/house-prices-and-images-socal/download\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/My Drive/Datasets\"\n",
        "!cp \"/content/drive/My Drive/Datasets/house-prices-and-images-socal.zip\" \"house-prices-and-images-socal.zip\"\n",
        "!unzip -q './house-prices-and-images-socal.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpG-AGDbyoAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset\n",
        "housing_csv = pd.read_csv(\"./socal2.csv\")\n",
        "\n",
        "# Create copy of housing data for modification\n",
        "housing_copy = housing_csv.copy()\n",
        "\n",
        "# Dataset basic info\n",
        "if verbose >= 1:\n",
        "  housing_csv.info()\n",
        "\n",
        "# Dataset histograms\n",
        "if verbose >= 2:\n",
        "  housing_csv.hist(figsize=(20,15), bins=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8nifhVFsxpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rows that are considered \"dirty\" and will be dropped\n",
        "dropped_rows = [0,5,7,14,33,37,50,56,77,90,101,129,165,182,212,223,231,191,193,226,233,237,300,305,332,357,366,367,373,380,391,413,412,477,482,490,493,488,492,500,501,505,531,538,548,545,550,555,572,579,577,583,593,603,604,615,627,682,702,717,737,747,752,776,784,785,801,802,798,810,826,848,872,877,889,888,903,906,911,931,975,989,997,999,994,1018,1039,1038,1040,1041,1042,1067,1086,1087,1093,1090,1095,1099,1104,1106,1107,1113,1114,1116,1124,1128,1134,1136,1147,1169,1173,1204,1208,1207,1214,1218,1227,1229,1233,1238,1241,1242,1244,1254,1251,1252,1257,1261,1262,1263,1268,1265,1270,1275,1280,1305,1312,1321,1326,1325,1329,1331,1335,1348,1361,1371,1390,1393,1396,1400,1407,1406,1412,1431,1441,1452,1458,1459,1465,1477,1487,1488,1494,1498,1502,1508,1510,1513,1528,1531,1551,1561,1567,1584,1592,1599,1607,1609,1617,1618,1622,1627,1626,1633,1638,1643,1644,1645,1648,1649,1651,1656,1652,1661,1674,1677,1678,1697,1725,1733,1772,1780,1781,1782,1785,1786,1793,1796,1805,1811,1825,1843,1856,1908,1915,1921,1925,1953,1955,1974,1980,1997,2017,2023,2024,2022,2026,2037,2047,2046,2096,2106,2107,2112,2113,2124,2132,2133,2136,2141,2142,2144,2149,2151,2153,2157,2158,2161,2182,2192,2196,2206,2220,2248,2256,2269,2271,2273,2278,2282,2287,2291,2290,2302,2303,2309,2334,2336,2345,2351,2367,2368,2385,2399,2423,2424,2425,2426,2436,2437,2441,2455,2458,2467,2470,2486,2501,2503,2502,2504,2507,2512,2517,2523,2525,2535,2537,2548,2554,2556,2566,2574,2575,2579,2592,2593,2600,2603,2609,2618,2623,2625,2632,2637,2649,2662,2671,2676,2679,2711,2713,2716,2728,2729,2748,2747,2750,2751,2754,2755,2756,2764,2765,2766,2775,2777,2783,2785,2800,2804,2806,2807,2811,2814,2816,2823,2825,2827,2833,2838,2845,2848,2855,2863,2866,2869,2867,2875,2878,2881,2882,2880,2893,2901,2908,2911,2910,2918,2919,2924,2948,2950,2952,2959,2968,2981,2989,2993,2995,2998,3001,3003,3007,3008,3013,3016,3017,3032,3044,3050,3051,3052,3053,3057,3058,3066,3075,3083,3084,3085,3092,3095,3099,3101,3103,3104,3107,3137,3147,3151,3154,3163,3167,3173,3177,3179,3182,3193,3203,3210,3216,3218,3219,3220,3222,3225,3236,3241,3244,3246,3245,3256,3261,3265,3272,3278,3294,3296,3298,3302,3306,3310,3312,3316,3319,3328,3336,3337,3340,3343,3346,3356,3360,3365,3366,3374,3371,3380,3384,3388,3390,3394,3411,3412,3415,3416,3422,3420,3428,3437,3451,3454,3460,3461,3464,3471,3474,3480,3484,3486,3490,3499,3497,3503,3510,3511,3516,3517,3518,3521,3524,3530,3532,3545,3546,3551,3554,3557,3558,3565,3569,3570,3575,3585,3589,3590,3595,3599,3601,3602,2605,3613,3614,3616,3625,3627,3632,3637,3638,3648,3649,3653,3655,3657,3668,3679,3682,3685,3686,3699,3705,3709,3721,3722,3733,3738,3742,3744,3747,3748,3751,3762,3768,3776,3787,3795,3804,3805,3809,3812,3819,3824,3825,3830,3840,3841,3842,3854,3855,3858,3859,3863,3864,3873,3865,3874,3876,3886,3888,3893,3895,3899,3906,3910,3931,3933,3935,3936,3937,3983,3940,3945,3948,3960,3967,3982,3988,3990,4002,3997,4000,4008,4009,4012,4013,4014,4020,4021,4022,4027,4031,4032,4034,4046,4060,4065,4066,4067,4070,4074,4079,4088,4089,4090,4095,4099,4102,4106,4107,4118,4119,4122,4124,4126,4128,4132,4133,4135,4142,4145,4146,4156,4160,4166,4168,4185,4189,4197,4198,4201,4205,4215,4223,4227,4228,4230,4244,4255,4258,4260,4264,4265,4268,4269,4272,4277,4278,4285,4289,4293,4309,4310,4311,4313,4313,4316,4319,4322,4329,4332,4334,4335,4346,4348,4353,4355,4357,4364,4375,4376,4380,4385,4389,4387,4369,4395,4408,4412,4423,4426,4428,4435,4447,4456,4461,4467,4468,4470,4479,4485,4486,4491,4496,4502,4507,4511,4512,4530,4533,4534,4535,4538,4554,4558,4562,4567,4568,4571,4574,4577,4579,4589,4594,4597,4598,4605,4606,4615,4616,4617,4618,4622,4635,4638,4641,4642,4646,4651,4653,4654,4659,4668,4670,4677,4690,4695,4696,4697,4703,4711,4714,4715,4716,4718,4720,4722,4726,4727,4730,4742,4744,4746,4754,4755,5757,4758,4761,4767,4775,4776,4778,4779,4781,4782,4784,4790,4796,4800,4801,4811,4813,4814,4815,4820,4821,4825,4826,4835,4838,4840,4850,4854,4855,4856,4861,4863,4864,4872,4874,4879,4891,4892,4893,4895,4896,4898,4914,4923,4925,4926,4927,4928,4929,4931,4936,4942,4945,4946,4949,4952,4957,4988,4989,4990,4991,5001,5011,5013,5014,5016,5017,5028,5029,5037,5029,5041,5043,5049,5058,5059,5062,5063,5066,5069,5074,5075,5076,5094,5098,5101,5107,5108,5117,5118,5119,5120,5121,5124,5127,5128,5129,5131,5132,5134,5135,5136,5142,5146,5152,5171,5175,5177,5179,5180,5181,5192,5193,5198,5204,5209,5214,5218,5231,5230,5239,5242,6246,5272,5285,5291,5293,5299,5304,5305,5308,5309,5312,5313,5317,5319,5321,5341,5352,5353,5368,5370,5371,5375,5367,5377,5385,5386,5396,5398,5399,5401,5403,5406,5407,5409,5411,5413,5414,5417,5421,5422,5423,5425,5427,5429,5430,5431,5433,5434,5435,5436,5437,5438,5439,5445,5447,5457,5458,5470,5474,5486,5487,5490,5491,5492,5495,5498,5507,5510,5511,5512,5516,5524,5525,5530,5533,5536,5538,5542,5551,5558,5565,5567,5568,5576,5591,5592,5595,5597,5600,5603,5608,5609,5616,5619,5621,5622,5628,5635,5637,5640,5648,5657,5658,5660,5661,5674,5675,5677,5678,5688,5690,5695,5696,5697,5699,5701,5703,5705,5706,5708,5712,5713,5714,5719,5718,5720,5722,5725,5727,5728,5729,5739,5741,5742,5744,5745,5746,5747,5748,5753,5757,5760,5761,5762,5769,5773,5782,5784,5792,5794,5795,5804,5806,5811,5823,5825,5827,5829,5833,5834,5836,5840,5844,5845,5847,5861,5862,5864,5866,5868,5875,5880,5883,5894,5900,5906,5905,5908,5911,5912,5913,5916,5917,5918,5919,5921,5924,5925,5930,5933,5934,5935,5940,5941,5942,5949,5951,5952,5953,5955,5957,5983,5996,5997,5998,6000,6002,6003,6009,6016,6018,6028,6029,6031,6034,6043,6047,6048,6052,6061,6063,6066,6068,6078,6081,6085,6087,6088,6100,6101,6103,6108,6109,6114,6115,6117,6118,6123,6129,6133,6142,6150,6155,6165,11250,11251,11255,11257,11261,11265,11267,11268,11269,11274,11277,11278,11281,11282,11283,11285,11287,11288,11289,11291,11294,11296,11299,11300,11301,11302,11304,11305,11306,11307,11308,11310,11311,11313,11315,11320,11324,11326,11328,11330,11331,11333,11338,11340,11342,11343,11344,11345,11349,11352,11354,11356,11361,11362,11364,11365,11368,11369,11371,11372,11373,11376,11382,11384,11386,11387,11395,11397,11400,11403,11405,11409,11412,11415,11416,11418,11421,11425,11427,11428,11429,11431,11436,11440,11442,11443,11445,11447,11457,11459,11462,11463,11469,11470,11476,11478,11480,11481,11485,11486,11487,11488,11492,11493,11495,11497,11500,11501,11502,11508,11513,11514,11515,11516,11517,11520,11521,11523,11524,11525,11528,11531,11532,11534,11537,11538,11539,11547,11550,11553,11558,11559,11561,11565,11567,11569,11572,11578,11586,11593,11594,11596,11598,11600,11602,11603,11604,11605,11608,11614,11621,11625,11627,11630,11633,11637,11639,11643,11644,11645,11646,11649,11650,11652,11654,11659,11663,11664,11667,11669,11675,11676,11677,11680,11682,11684,11685,11686,11687,11693,11701,11703,11708,11710,11713,11714,11715,11716,11720,11729,11731,11737,11739,11741,11744,11745,11746,11747,11748,11753,11755,11761,11763,11767,11770,11776,11777,11780,11783,11785,11786,11787,11788,11789,11793,11795,11798,11799,11802,11811,11815,11821,11822,11823,11833,11836,11837,11840,11841,11845,11847,11849,11865,11866,11871,11875,11876,11894,11897,11902,11917,11923,11924,11926,11927,11932,11933,11934,11935,11936,11939,11941,11942,11949,11956,11957,11958,11961,11967,11970,11971,11976,11978,11980,11981,11982,11983,11984,11985,11986,11988,11992,11996,11997,11998,11999,12000,12003,12005,12006,12010,12017,12024,12025,12027,12035,12037,12038,12041,12055,12056,12061,12066,12067,12069,12071,12072,12074,12075,12076,12077,12080,12087,12090,12101,12106,12107,12111,12112,12114,12116,12120,12125,12129,12130,12134,12144,12146,12150,12154,12160,12162,12163,12166,12169,12171,12176,12181,12183,12184,12186,12189,12190,12195,12198,12205,12208,12214,12219,12227,12228,12232,12234,12237,12238,12249,12252,12256,12260,12262,12266,12267,12269,12270,12271,12273,12275,12280,12285,12287,12289,12290,12294,12295,12298,12301,12304,12306,12307,12315,12316,12319,12320,12322,12325,12332,12336,12340,12344,12345,12349,12352,12355,12357,12358,12361,12363,12371,12376,12377,12378,12379,12380,12384,12386,12387,12394,12397,12398,12423,12429,12431,12434,12441,12443,12446,12448,12449,12451,12453,12456,12459,12462,12463,12466,12468,12475,12477,12479,12485,12486,12491,12493,12498,12499,12503,12504,12506,12511,12514,12515,12525,12526,12531,12536,12542,12546,12547,12548,12549,12550,12558,12559,12564,12572,12574,12575,12577,12581,12582,12587,12588,12590,12592,12593,12595,12596,12597,12598,12599,12605,12613,12619,12623,12628,12631,12632,12634,12639,12642,12652,12657,12660,12663,12666,12669,12670,12676,12677,12682,12685,12686,12687,12688,12689,12690,12697,12699,12700,12701,12702,12703,12704,12708,12710,12711,12714,12716,12717,12723,12724,12726,12730,12740,12743,12746,12748,12749,12754,12758,12760,12761,12763,12767,12769,12771,12772,12777,12781,12785,12788,12794,12795,12799,12800,12802,12804,12806,12807,12812,12813,12821,12830,12831,12832,12841,12843,12849,12858,12861,12863,12865,12869,12873,12879,12880,12889,12899,12900,12912,12916,12921,12926,12932,12934,12937,12938,12955,12958,12962,12967,12970,12978,12980,12988,12992,13000,13002,13010,13016,13020,13022,13026,13028,13029,13032,13037,13038,13039,13040,13043,13050,13055,13058,13060,13062,13063,13064,13065,13068,13070,13072,13076,13077,13078,13080,13081,13087,13089,13090,13096,13101,13111,13112,13113,13114,13117,13126,13129,13131,13132,13133,13136,13140,13141,13142,13148,13150,13155,13156,13158,13171,13178,13190,13193,13197,13199,13200,13201,13214,13215,13223,13228,13229,13231,13238,13240,13244,13245,13250,13252,13254,13256,13260,13262,13264,13265,13271,13277,13279,13289,13293,13294,13295,13296,13301,13308,13311,13312,13320,13322,13326,13331,13332,13334,13335,13337,13339,13344,13348,13354,13355,13358,13359,13360,13362,13363,13368,13370,13375,13376,13337,13381,13385,13386,13387,13389,13393,13394,13396,13410,13413,13417,13424,13425,13439,13441,13443,13448,13449,13457,13459,13460,13463,13484,13487,13490,13491,13492,13494,13495,13502,13506,13507,13509,13513,13524,13530,13531,13532,13533,13537,13540,13544,13551,13555,13559,13563,13566,13567,13569,13570,13572,13573,13575,13576,13577,13578,13580,13582,13584,13587,13595,13596,13598,13599,13602,13604,13614,13616,13619,13620,13621,13622,13625,13632,13633,13636,13637,13640,13652,13655,13658,13659,13661,13662,13663,13669,13671,13674,13675,13680,13681,13682,13693,13696,13700,13706,13709,13711,13712,13716,13718,13724,13730,13732,13735,13736,13744,13749,13751,13754,13760,13764,13769,13772,13774,13776,13780,13786,13793,13795,13796,13805,13806,13812,13813,13815,13821,13822,13823,13827,13831,13835,13837,13839,13844,13847,13849,13853,13855,13856,13863,13869,13872,13877,13879,13881,13882,13887,13899,13900,13906,13908,13909,13911,13912,13918,13928,13931,13933,13937,13942,13946,13947,13952,13955,13962,13970,13975,13976,13983,13987,13988,13989,13991,13993,13996,13999,14006,14007,14010,14017,14020,14022,14023,14024,14025,14030,14032,14034,14038,14043,14044,14049,14050,14051,14053,14054,14059,14062,14067,14072,14075,14077,14078,14079,14087,14092,14094,14097,14099,14101,14105,14107,14111,14113,14117,14121,14122,14123,14124,14125,14126,14127,14128,14139,14140,14145,14146,14147,14148,14149,14150,14151,14162,14167,14173,14174,14175,14176,14179,14183,14184,14186,14188,14190,14192,14197,14202,14209,14212,14224,14227,14228,14229,14230,14231,14234,14238,14249,14250,14254,14256,14257,14258,14263,14268,14269,14270,14280,14282,14287,14307,14308,14309,14330,14338,14342,14343,14344,14345,14346,14347,14348,14349,14353,14355,14356,14357,14358,14359,14360,14361,14362,14363,14369,14370,14371,14372,14379,14392,14415,14426,14431,14440,14449,14453,14454,14458,14468,14469,14472,14476,14478,14481,14486,14488,14494,14495,14499,14501,14504,14505,14510,14519,14525,14527,14529,14533,14535,14541,14544,14548,14550,14551,14559,14562,14564,14565,14567,14570,14571,14578,14580,14583,14585,14591,14593,14595,14599,14603,14604,14611,14612,14617,14621,14622,14624,14628,14635,14641,14647,14655,14656,14660,14671,14682,14683,14687,14691,14692,14695,14697,14699,14703,14704,14705,14706,14707,14708,14712,14713,14714,14715,14721,14722,14728,14733,14739,14740,14752,14755,14762,14766,14767,14769,14771,14777,14778,14783,14784,14790,14792,14793,14798,14802,14806,14807,14809,14810,14825,14837,14839,14840,14842,14853,14860,14869,14875,14878,14889,14890,14896,14901,14911,14921,14926,14929,14933,14935,14937,14941,14957,14958,14961,14968,14969,14970,14971,14976,14977,14985,14987,14989,14991,15003,15006,15011,15014,15020,15023,15026,15031,15033,15045,15046,15047,15048,15055,15060,15065,15068,15072,15076,15083,15085,15088,15089,15090,15105,15110,15111,15122,15124,15133,15135,15137,15140,15145,15146,15149,15158,15161,15162,15167,15178,15179,15180,15181,15182,15184,15189,15190,15208,15213,15215,15217,15218,15223,15229,15230,15233,15236,15248,15250,15253,15259,15264,15269,15270,15275,15280,15304,15312,15323,15325,15337,15345,15346,15368,15371,15375,15376,15377,15382,15383,15390,15391,15402,15404,15405,15407,15408,15412,15420,15422,15426,15432,15434,15441,15447,15451,15453,15454,15456,15457,15461,15465,15467,15468,15471,15473,7004,7006,7007,7010,7012,7013,7015,7017,7026,7028,7029,7030,7033,7034,7035,7037,7038,7039,7040,7042,7045,7056,7060,7062,7065,7066,7071,7079,7082,7083,7085,7087,7089,7090,7092,7093,7096,7097,7098,7100,7101,7108,7109,7112,7113,7116,7120,7121,7122,7124,7125,7131,7132,7136,7142,7143,7144,7148,7152,7156,7157,7159,7162,7163,7164,7173,7175,7177,7179,7182,7184,7185,7186,7189,7190,7193,7194,7195,7198,7202,7203,7204,7207,7208,7210,7211,7212,7215,7217,7223,7228,7231,7240,7246,7247,7248,7252,7253,7254,7257,7260,7264,7265,7269,7271,7272,7276,7278,7279,7280,7286,7290,7291,7297,7302,7303,7307,7309,7316,7317,7319,7321,7322,7323,7325,7327,7333,7335,7336,7338,7339,7341,7342,7343,7347,7349,7350,7352,7364,7366,7373,7374,7378,7381,7384,7386,7389,7390,7391,7392,7400,7403,7408,7410,7416,7422,7424,7428,7433,7441,7443,7449,7451,7454,7457,7458,7463,7468,7469,7470,7474,7475,7476,7481,7482,7483,7484,7485,7488,7491,7493,7495,7496,7500,7501,7503,7518,7520,7523,7525,7526,7532,7533,7534,7535,7539,7540,7541,7542,7543,7544,7545,7547,7549,7551,7552,7554,7555,7560,7562,7563,7564,7565,7568,7570,7574,7578,7579,7581,7583,7586,7587,7589,7591,7592,7593,7595,7598,7601,7603,7606,7608,7609,7611,7612,7616,7617,7619,7622,7627,7628,7629,7630,7631,7632,7633,7634,7635,7637,7638,7639,7641,7642,7643,7644,7647,7648,7649,7653,7660,7661,7664,7667,7668,7672,7676,7677,7678,7679,7680,7681,7682,7684,7685,7687,7688,7696,7698,7699,7702,7703,7705,7707,7711,7714,7723,7728,7729,7733,7736,7738,7739,7743,7745,7747,7750,7751,7752,7753,7757,7758,7759,7761,7762,7768,7771,7772,7773,7778,7791,7794,7795,7796,7797,7798,7800,7803,7808,7814,7816,7817,7818,7820,7822,7823,7825,7826,7828,7831,7832,7833,7834,7835,7836,7837,7842,7843,7844,7847,7848,7851,7852,7853,7854,7855,7856,7858,7862,7868,7869,7872,7874,7876,7877,7882,7884,7885,7886,7887,7888,7889,7890,7892,7893,7894,7896,7905,7907,7908,7914,7916,7918,7921,7922,7927,7928,7929,7931,7932,7933,7934,7936,7941,7950,7952,7958,7964,7965,7968,7969,7970,7973,7975,7977,7978,7979,7980,7982,7983,7984,7985,7986,7987,7993,7995,7996,7997,7998,7999,8000,8001,8003,8008,8009,8010,8016,8017,8019,8020,8021,8023,8024,8025,8027,8028,8030,8032,8034,8036,8041,8042,8043,8044,8045,8049,8056,8057,8059,8060,8061,8063,8064,8065,8068,8069,8070,8072,8077,8081,8084,8085,8087,8091,8095,8099,8102,8114,8115,8121,8134,8144,8145,8146,8147,8153,8154,8155,8157,8173,8181,8185,8186,8192,8193,8194,8195,8196,8197,8201,8207,8208,8210,8211,8214,8215,8216,8221,8223,8228,8229,8230,8237,8238,8241,8244,8246,8254,8255,8256,8260,8266,8271,8274,8275,8278,8290,8294,8295,8306,8311,8314,8323,8327,8328,8339,8342,8346,8360,8366,8384,8388,8391,8395,8403,8408,8410,8417,8424,8426,8428,8429,8438,8440,8447,8457,8460,8461,8464,8467,8469,8476,8481,8483,8495,8503,8508,8521,8523,8527,8534,8536,8541,8542,8544,8548,8554,8556,8558,8561,8563,8572,8589,8604,8618,8621,8623,8632,8635,8638,8644,8647,8654,8660,8664,8665,8668,8670,8679,8680,8685,8688,8689,8691,8694,8706,8707,8709,8715,8722,8733,8741,8742,8744,8746,8747,8756,8764,8768,8769,8781,8786,8793,8794,8805,8809,8812,8813,8817,8821,8824,8830,8837,8849,8852,8863,8864,8865,8877,8883,8886,8889,8890,8895,8899,8901,8902,8904,8906,8907,8908,8913,8915,8919,8921,8928,8929,8931,8934,8938,8947,8954,8955,8959,8960,8971,8980,8984,8989,8990,8992,8999,9007,9013,9014,9015,9017,9021,9043,9057,9060,9062,9068,9071,9078,9081,9083,9084,9093,9094,9097,9102,9103,9110,9117,9119,9124,9125,9127,9138,9140,9141,9153,9160,9161,9163,9168,9172,9175,9178,9179,9180,9182,9184,9190,9194,9204,9209,9211,9213,9218,9220,9225,9230,9233,9235,9237,9242,9260,9266,9272,9276,9283,9293,9294,9296,9297,9298,9299,9300,9301,9302,9303,9304,9305,9312,9314,9318,9332,9338,9359,9364,9367,9371,9372,9381,9383,9393,9396,9399,9405,9419,9420,9423,9430,9437,9441,9444,9450,9460,9482,9487,9491,9492,9494,9498,9505,9506,9513,9524,9553,9560,9566,9569,9572,9577,9581,9582,9585,9592,9593,9597,9599,9601,9614,9616,9622,9630,9633,9645,9647,9648,9666,9685,9686,9691,9695,9697,9701,9702,9706,9707,9714,9716,9719,9720,9722,9723,9728,9729,9730,9732,9737,9743,9751,9753,9760,9761,9765,9766,9771,9772,9773,9786,9787,9797,9802,9803,9814,9817,9818,9824,9825,9828,9833,9836,9837,9841,9842,9847,9848,9849,9851,9853,9854,9856,9864,9866,9876,9882,9884,9885,9899,9902,9906,9909,9918,9921,9926,9927,9938,9944,9952,9955,9956,9959,9960,9961,9963,9965,9987,9992,9993,9996,10000,10005,10011,10016,10020,10028,10049,10058,10059,10065,10072,10075,10080,10082,10083,10086,10091,10095,10096,10103,10105,10111,10115,10116,10123,10125,10131,10140,10141,10145,10149,10156,10160,10163,10167,10169,10170,10173,10177,10179,10180,10181,10183,10188,10219,10226,10231,10234,10237,10241,10248,10252,10256,10260,10261,10264,10266,10267,10268,10270,10282,10283,10285,10294,10298,10300,10302,10307,10313,10316,10320,10322,10328,10329,10330,10335,10338,10339,10344,10350,10351,10355,10357,10361,10363,10366,10367,10373,10375,10382,10389,10391,10392,10395,10403,10404,10406,10411,10412,10417,10420,10424,10431,10438,10440,10442,10445,10450,10451,10453,10462,10465,10467,10468,10473,10477,10480,10483,10485,10488,10491,10493,10497,10501,10502,10503,10508,10509,10510,10512,10528,10534,10551,10558,10561,10565,10567,10576,10579,10583,10584,10587,10588,10589,10591,10592,10593,10603,10604,10606,10609,10611,10613,10614,10623,10640,10641,10645,10652,10655,10658,10668,10670,10671,10673,10676,10683,10686,10687,10688,10693,10697,10698,10700,10702,10703,10704,10706,10708,10709,10710,10714,10715,10720,10724,10725,10726,10727,10729,10730,10731,10732,10734,10738,10739,10740,10741,10745,10746,10747,10748,10749,10754,10755,10757,10758,10760,10761,10762,10765,10769,10770,10771,10772,10777,10778,10779,10782,10786,10787,10793,10794,10795,10797,10798,10799,10801,10802,10807,10811,10812,10814,10815,10816,10817,10818,10819,10820,10821,10822,10828,10833,10834,10835,10836,10837,10838,10839,10842,10843,10846,10851,10852,10857,10858,10868,10869,10870,10872,10874,10877,10879,10881,10882,10883,10886,10887,10888,10889,10893,10894,10898,10899,10901,10905,10907,10909,10910,10912,10915,10917,10922,10923,10924,10927,10932,10933,10935,10936,10938,10939,10941,10942,10943,10946,10947,10949,10950,10953,10955,10959,10960,10961,10962,10967,10968,10969,10970,10971,10972,10974,10975,10976,10980,10982,10983,10987,10992,10996,10997,11000,11002,11003,11005,11009,11012,11013,11019,11020,11022,11023,11025,11031,11032,11033,11035,11036,11044,11045,11047,11051,11052,11056,11058,11059,11060,11062,11064,11065,11067,11068,11069,11070,11073,11078,11080,11081,11083,11084,11086,11089,11090,11091,11092,11093,11095,11100,11102,11104,11106,11110,11113,11114,11117,11118,11122,11128,11138,11140,11143,11145,11147,11152,11153,11154,11156,11157,11158,11161,11165,11167,11168,11170,11173,11175,11182,11183,11185,11189,11190,11191,11192,11194,11198,11200,11201,11203,11209,11210,11212,11215,11217,11218,11220,11222,11223,11224,11225,11227,11228,11229,11230,11231,11234,11237]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F301Mq8FtSXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop \"dirty\" rows\n",
        "housing_copy.drop(housing_copy.index[dropped_rows], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Ir167vGzmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data modification\n",
        "\n",
        "# Concatenate beds + baths into new 'rooms' to increase correlation\n",
        "housing_copy['rooms'] = housing_copy['bed'] + housing_copy['bath']\n",
        "\n",
        "# Drop low correlation arguments in the dataset\n",
        "dropped_args = [\n",
        "           'street',\n",
        "           'citi',\n",
        "           'image_id',\n",
        "]\n",
        "housing_copy = housing_copy.drop(dropped_args, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoVZ-k0LCT4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print correlation matrix to show the realtion of all args in the table to price\n",
        "if verbose >= 1:\n",
        "  corr_matrix = housing_copy.corr()\n",
        "  corr_matrix[\"price\"].sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzFnzr1F7KIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a list of all photos for the dataset, resized for training\n",
        "def generate_house_photos(df, base_path, extension='.jpg'):\n",
        "  photos = []\n",
        "\n",
        "  # Prevent dropped rows' images from being included\n",
        "  not_dropped = list(filter(lambda x: x not in dropped_rows, df.index.values))\n",
        "\n",
        "  for index in not_dropped:\n",
        "    # Reshaped image will be [128 x 128]\n",
        "    output_image = np.zeros((128, 128, 3), dtype=\"uint8\")\n",
        "\n",
        "    photo_path = os.path.join(base_path, str(index) + extension)\n",
        "    photo = cv2.imread(photo_path)\n",
        "    photo = cv2.resize(photo, (128, 128))\n",
        "    output_image[0:128, 0:128] = photo\n",
        "\n",
        "    photos.append(output_image)\n",
        "  \n",
        "  return np.array(photos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvaT4Vf_5u3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate the photos for the dataset\n",
        "housing_photos = generate_house_photos(housing_csv, 'socal2/socal_pics')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU6HpjJfhgRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the CNN branch of the concatenated model\n",
        "def create_photo_model_branch(in_w, in_h, in_d, filters=[32, 64, 128, 256], regress=False):\n",
        "  \n",
        "  input_dims = (in_h, in_w, in_d)\n",
        "  channel_dim = -1\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=input_dims) \n",
        "  x = None\n",
        "  for index, filter in zip(range(len(filters)), filters):\n",
        "    if index == 0:\n",
        "      x = inputs\n",
        "    x = tf.keras.layers.Conv2D(filter, (3, 3), padding=\"same\" )(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)  \n",
        "    x = tf.keras.layers.BatchNormalization(axis=channel_dim)(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = (tf.keras.layers.Dropout(0.5))(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(2048)(x)\n",
        "  x = tf.keras.layers.Dense(2048)(x)\n",
        "  if regress:\n",
        "    x = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "  return tf.keras.Model(inputs, x)\n",
        "  \n",
        "if verbose >= 1:\n",
        "  cnn_model = create_photo_model_branch(128, 128, 3)\n",
        "  cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSASsYYdEF0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the MLP branch of the concatenated model\n",
        "\n",
        "def create_mlp(dim, regress=False):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(128, input_dim=dim, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(0.4))\n",
        "  model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "  if regress:\n",
        "    model.add(tf.keras.layers.Dense(1, activation=\"linear\"))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoiGZXh7goaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipeline used to process the data for training\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
        "\n",
        "def process_house_attributes(df, train_data, test_data):\n",
        "  # All the continuous arguments in the dataset\n",
        "  continuous = [\"bed\", \"bath\", \"sqft\", \"rooms\"]\n",
        "\n",
        "  # MinMaxScalar will scale the values in a column according to the min/max relation of the column\n",
        "  cs = MinMaxScaler()\n",
        "  \n",
        "  # Create the train/test sets for the continuous data columns\n",
        "  trainContinuous, testContinuous = (cs.fit_transform(train_data[continuous]), cs.transform(test_data[continuous]))\n",
        "\n",
        "  # LabelBinarizer will create a sparse matrix in place of the column value rathet than the numerical one\n",
        "  zipBinarizer = LabelBinarizer().fit(df[\"n_citi\"])\n",
        "  \n",
        "  # Create the train/test sets for the categorical data columns\n",
        "  trainCategorical, testCategorical = (zipBinarizer.transform(train_data[\"n_citi\"]), zipBinarizer.transform(test_data[\"n_citi\"]))\n",
        "\n",
        "  # Concatenate arrays to create complete train/test sets\n",
        "  trainSet = np.hstack([trainCategorical, trainContinuous])\n",
        "  testSet = np.hstack([testCategorical, testContinuous])\n",
        "\n",
        "  return (trainSet, testSet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql6Z_rp9LJ4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Block used to scale and de-scale the training and testing prices by a fixed max price\n",
        "def scale_prices(train_prices, test_prices, max_price):\n",
        "  train_prices = train_prices / max_price\n",
        "  test_prices = test_prices / max_price\n",
        "  return (train_prices, test_prices)\n",
        "\n",
        "def de_scale_price(arrs, max_price):\n",
        "  for arr in arrs:\n",
        "    arr = arr * max_price"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23WApCwDMAVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learning models parameters\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "test_ratio = 0.25\n",
        "random_state = 42\n",
        "learning_rate = 0.0001\n",
        "epochs = 45\n",
        "batch_size = 32\n",
        "model_verbose = 0\n",
        "callbacks = []\n",
        "optimizer = tf.keras.optimizers.Adam\n",
        "loss = \"mean_squared_error\"\n",
        "metrics = []\n",
        "\n",
        "if verbose >= 2:\n",
        "  callbacks.append(PlotLossesKeras())\n",
        "elif verbose >= 1:\n",
        "  model_verbose = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAA1lyghiBn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split tabular data using a random state\n",
        "split_tab = train_test_split(housing_copy, test_size=test_ratio, random_state=random_state)\n",
        "(train_tab, test_tab) = split_tab\n",
        "\n",
        "# Preprocess the split data\n",
        "(train_tab, test_tab) = process_house_attributes(housing_copy, train_tab, test_tab)\n",
        "\n",
        "# Split image data using a random state\n",
        "split_images = train_test_split(housing_photos, test_size=test_ratio, random_state=random_state)\n",
        "(train_images, test_images) = split_images\n",
        "\n",
        "# Split prices (ie. labels) using a random state\n",
        "split_prices = train_test_split(housing_copy['price'], test_size=test_ratio, random_state=random_state)\n",
        "(train_prices, test_prices) = split_prices\n",
        "\n",
        "# Scale the prices by the max price\n",
        "train_prices, test_prices = scale_prices(train_prices, test_prices, housing_copy['price'].max())\n",
        "\n",
        "# Generate the model branches with regression False, meaning no single output node\n",
        "cnn_model = create_photo_model_branch(128, 128, 3, regress=False)\n",
        "mlp_model = create_mlp(train_tab.shape[1], regress=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fripCh4KvToh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN Model if used with regression\n",
        "# ie. predicting prices using only images\n",
        "\n",
        "cnn_model.compile(loss=loss, optimizer=optimizer(learning_rate), metrics=metrics)\n",
        "cnn_model.fit(\n",
        "\ttrain_images, train_prices,\n",
        "  validation_data=(test_images, test_prices),\n",
        "\tepochs=epochs, \n",
        "  batch_size=batch_size,\n",
        "  verbose=model_verbose,\n",
        "  callbacks=model_verbose\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUehgWBrWcjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MLP Model if used with regression\n",
        "# ie. predicting prices using only tabular data\n",
        "\n",
        "mlp_model.compile(loss=loss, optimizer=optimizer(learning_rate), metrics=metrics)\n",
        "mlp_model.fit(\n",
        "\ttrain_tab, train_prices,\n",
        "\tvalidation_data=(test_tab, test_prices),\n",
        "\tepochs=epochs, \n",
        "  batch_size=batch_size,\n",
        "  verbose=model_verbose,\n",
        "  callbacks=callbacks\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckwt4qtpqQiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the final branch of the model (concatenated input branch)\n",
        "concatenatedInput = tf.keras.layers.concatenate([mlp_model.output, cnn_model.output])\n",
        "\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(concatenatedInput)\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\")(concatenatedInput)\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(concatenatedInput)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(concatenatedInput)\n",
        "x = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "concat_model = tf.keras.Model(inputs=[mlp_model.input, cnn_model.input], outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMIZHCbpqw5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenated Model which connects the CNN and the MLP output\n",
        "# ie. predicting prices using both image and tabular data\n",
        "\n",
        "concat_model.compile(loss=loss, optimizer=optimizer(learning_rate), metrics=metrics)\n",
        "\n",
        "concat_model.fit(\n",
        "\t[train_tab, train_images], train_prices,\n",
        "\tvalidation_data=([test_tab, test_images], test_prices),\n",
        "\tepochs=epochs, \n",
        "  batch_size=batch_size,\n",
        "  verbose=model_verbose,\n",
        "  callbacks=callbacks\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYl8JjYC7XXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Results of the concatenated model through the display of average dollar value loss\n",
        "\n",
        "# Predicitons based on a concatenated input of image and tabular data\n",
        "concat_preds = concat_model.predict([test_tab, test_images])\n",
        "\n",
        "de_scale_price([concat_preds, test_prices], max_price)\n",
        "\n",
        "total_loss = 0\n",
        "num_houses = len(test_prices_scaled)\n",
        "for predicted, real in zip(concat_preds, test_prices_scaled):\n",
        "  total_loss += np.abs(real - predicted[0])\n",
        "\n",
        "if verbose >= 1:\n",
        "  print(\"Average Loss: ${:,.2f}\".format(total_loss / num_houses))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}